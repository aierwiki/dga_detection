{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_malicious():\n",
    "    import re\n",
    "    records = []\n",
    "    with open('./data/dga.txt') as f:\n",
    "        records = re.findall(r'(\\w+)\\t+([\\w.]+).*\\n', f.read())\n",
    "    df_malicious = pd.DataFrame({'Domain':[record[1] for record in records], 'Label':[record[0] for record in records]})\n",
    "    return df_malicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benign():\n",
    "    df_benign = pd.read_csv('./data/top-1m.csv', index_col = 0, header = None)\n",
    "    df_benign.columns = ['Domain']\n",
    "    df_benign['Label'] = 'benign'\n",
    "    return df_benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    import tldextract\n",
    "    df_malicious = get_malicious()\n",
    "    df_benign = get_benign()\n",
    "    df_data = pd.concat([df_malicious, df_benign], axis = 0)\n",
    "    df_data['Target'] = df_data['Label'].map(lambda x : 0 if x == 'benign' else 1)\n",
    "    df_data['Domain'] = df_data['Domain'].map(lambda x : tldextract.extract(x).domain)\n",
    "    df_data = df_data.drop_duplicates(subset = ['Domain'])\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(df_data):\n",
    "    df_data_small = pd.concat([df_data[df_data['Target'] == 0].sample(500000), df_data[df_data['Target'] == 1].sample(300000)], axis = 0)\n",
    "    X = df_data_small['Domain'].values\n",
    "    y = df_data_small['Target'].values\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 2019, test_size = 0.2)\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "    tokenizer = Tokenizer(char_level = True)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    X_train = pad_sequences(X_train, padding = 'post')\n",
    "    X_test = pad_sequences(X_test, padding = 'post', maxlen = X_train.shape[1])\n",
    "    return X_train, X_test, y_train, y_test, tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(words_num, max_length, feature_num):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Embedding, LSTM, Dense, Dropout, Activation\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim = words_num, output_dim = feature_num, input_length = max_length))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    import keras.backend as K\n",
    "    def calc_recall_score(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "\n",
    "    def calc_precision_score(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "\n",
    "    def calc_f1_score(y_true, y_pred):\n",
    "        precision = calc_precision_score(y_true, y_pred)\n",
    "        recall = calc_recall_score(y_true, y_pred)\n",
    "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', \n",
    "                  metrics = ['acc', calc_recall_score, calc_precision_score, calc_f1_score])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_test, y_train, y_test, word_index):\n",
    "    model = build_model(len(word_index) + 1, X_train.shape[1], 128)\n",
    "    model.fit(X_train, y_train, batch_size = 128, epochs = 5, validation_split = 0.3)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, word_index = make_data(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 448000 samples, validate on 192000 samples\n",
      "Epoch 1/5\n",
      "448000/448000 [==============================] - 473s 1ms/step - loss: 0.1648 - acc: 0.9372 - calc_recall_score: 0.8832 - calc_precision_score: 0.9243 - calc_f1_score: 0.9000 - val_loss: 0.0875 - val_acc: 0.9685 - val_calc_recall_score: 0.9209 - val_calc_precision_score: 0.9944 - val_calc_f1_score: 0.9557\n",
      "Epoch 2/5\n",
      "448000/448000 [==============================] - 473s 1ms/step - loss: 0.0581 - acc: 0.9817 - calc_recall_score: 0.9660 - calc_precision_score: 0.9850 - calc_f1_score: 0.9751 - val_loss: 0.0463 - val_acc: 0.9854 - val_calc_recall_score: 0.9774 - val_calc_precision_score: 0.9833 - val_calc_f1_score: 0.9802\n",
      "Epoch 3/5\n",
      "448000/448000 [==============================] - 474s 1ms/step - loss: 0.0438 - acc: 0.9863 - calc_recall_score: 0.9753 - calc_precision_score: 0.9882 - calc_f1_score: 0.9815 - val_loss: 0.0385 - val_acc: 0.9876 - val_calc_recall_score: 0.9734 - val_calc_precision_score: 0.9934 - val_calc_f1_score: 0.9831\n",
      "Epoch 4/5\n",
      "448000/448000 [==============================] - 475s 1ms/step - loss: 0.0368 - acc: 0.9884 - calc_recall_score: 0.9797 - calc_precision_score: 0.9894 - calc_f1_score: 0.9844 - val_loss: 0.0473 - val_acc: 0.9865 - val_calc_recall_score: 0.9730 - val_calc_precision_score: 0.9906 - val_calc_f1_score: 0.9815\n",
      "Epoch 5/5\n",
      "448000/448000 [==============================] - 474s 1ms/step - loss: 0.0333 - acc: 0.9898 - calc_recall_score: 0.9824 - calc_precision_score: 0.9904 - calc_f1_score: 0.9863 - val_loss: 0.0327 - val_acc: 0.9893 - val_calc_recall_score: 0.9788 - val_calc_precision_score: 0.9924 - val_calc_f1_score: 0.9854\n"
     ]
    }
   ],
   "source": [
    "model = train(X_train, X_test, y_train, y_test, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
